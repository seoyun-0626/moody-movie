# ==========================================================
# ğŸ¬ Moody-Movie Flask ì„œë²„ (ê°ì • ê¸°ë°˜ ì˜í™” ì¶”ì²œ ì±—ë´‡)
# ==========================================================
# ì´ ì„œë²„ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì—­í• ì„ ìˆ˜í–‰í•¨:
# â‘  ê°ì • ë¶„ì„ (ëŒ€í‘œê°ì • + ì„¸ë¶€ê°ì •)
# â‘¡ ê°ì • ê¸°ë°˜ ì˜í™” ì¶”ì²œ
# â‘¢ ê°ì •ìƒë‹´ ì±—ë´‡ ëŒ€í™” (3í„´ êµ¬ì¡°)
# â‘£ DB ì—°ê²° (í†µê³„ ë° ì¸ê¸° ì˜í™” ì¡°íšŒ)
# ==========================================================

import json
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from flask.json.provider import DefaultJSONProvider
import pickle, random, sys
from openai import OpenAI
from movie_api import get_movies_by_genre, get_movie_rating
from dotenv import load_dotenv
import os
import pymysql

# ==========================================================
# âœ… 1. ê²½ë¡œ ì„¤ì • (ì ˆëŒ€ê²½ë¡œ)
# ==========================================================
BASE_DIR = r"C:\ai-project\moody-movie"             # í”„ë¡œì íŠ¸ ê¸°ë³¸ ê²½ë¡œ
MODEL_DIR = os.path.join(BASE_DIR, "models")        # ëª¨ë¸ íŒŒì¼ í´ë”
ENV_PATH = r"C:\ai-project\.env"                    # í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ê²½ë¡œ (.env)

# ==========================================================
# âœ… 2. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì—ì„œ í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°)
# ==========================================================
load_dotenv(dotenv_path=ENV_PATH)
api_key = os.getenv("OPENAI_API_KEY")                # OpenAI API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
print(f"ğŸ”‘ OpenAI Key ë¶ˆëŸ¬ì˜´: {api_key[:10]}..." if api_key else "âŒ OpenAI Key ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = OpenAI(api_key=api_key)

# ==========================================================
# âœ… 3. Flask ì•± ê¸°ë³¸ ì„¤ì •
# ==========================================================
app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})       # ëª¨ë“  ë„ë©”ì¸ì—ì„œ ì ‘ê·¼ í—ˆìš© (CORS ë¬¸ì œ ë°©ì§€)
app.config["JSON_AS_ASCII"] = False                  # jsonifyê°€ í•œê¸€ì„ ASCIIë¡œ ë³€í™˜í•˜ì§€ ì•Šê²Œ ì„¤ì •

# UTF-8 JSON ì¸ì½”ë”© ë³´ì¥ìš© ì»¤ìŠ¤í…€ Provider
class UTF8JSONProvider(DefaultJSONProvider):
    def dumps(self, obj, **kwargs):
        kwargs.setdefault("ensure_ascii", False)     # í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šë„ë¡
        return json.dumps(obj, **kwargs)
    def loads(self, s, **kwargs):
        return json.loads(s, **kwargs)

app.json = UTF8JSONProvider(app)
sys.stdout.reconfigure(encoding="utf-8")             # ì½˜ì†” ì¶œë ¥ ì‹œ í•œê¸€ ê¹¨ì§ ë°©ì§€

# ==========================================================
# âœ… 4. ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ
# ==========================================================
try:
    # ëª¨ë¸ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (ëŒ€í‘œê°ì • + ì„¸ë¶€ê°ì •)
    model = pickle.load(open(os.path.join(MODEL_DIR, "emotion_model.pkl"), "rb"))
    sub_model = pickle.load(open(os.path.join(MODEL_DIR, "sub_models.pkl"), "rb"))          # âœ… ì—¬ê¸° ìˆ˜ì •
    vectorizer = pickle.load(open(os.path.join(MODEL_DIR, "vectorizer.pkl"), "rb"))
    sub_vectorizer = pickle.load(open(os.path.join(MODEL_DIR, "sub_vectorizers.pkl"), "rb")) # âœ… ì—¬ê¸° ìˆ˜ì •
    print("âœ… ê°ì • ë¶„ì„ ëª¨ë¸ ë° ì„¸ë¶€ê°ì • ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit()
    
# ==========================================================
# âœ… 5. ê°ì • â†’ ì˜í™” ì¥ë¥´ ë§¤í•‘ í…Œì´ë¸”
# ==========================================================
emotion_to_genre = {
    "ë¶„ë…¸": [28, 80, 53, 27, 9648],         # ì•¡ì…˜, ë²”ì£„, ìŠ¤ë¦´ëŸ¬
    "ë¶ˆì•ˆ": [53, 9648, 18, 878],            # ìŠ¤ë¦´ëŸ¬, ë¯¸ìŠ¤í„°ë¦¬, ë“œë¼ë§ˆ, SF
    "ìŠ¤íŠ¸ë ˆìŠ¤": [35, 10402, 10751, 16],     # ì½”ë¯¸ë””, ìŒì•…, ê°€ì¡±, ì• ë‹ˆë©”ì´ì…˜
    "ìŠ¬í””": [18, 10749, 10751, 99],         # ë“œë¼ë§ˆ, ë¡œë§¨ìŠ¤, ê°€ì¡±, ë‹¤í
    "í–‰ë³µ": [35, 16, 10751, 10402],         #  ì½”ë¯¸ë””, ì• ë‹ˆ, ê°€ì¡±, ìŒì•…
    "ì‹¬ì‹¬": [14, 878, 12, 10751,27],         # íŒíƒ€ì§€, SF, ëª¨í—˜, ê°€ì¡±
    "íƒêµ¬": [99, 36, 18, 37],               # ë‹¤í, ì—­ì‚¬, ë“œë¼ë§ˆ, ì„œë¶€ê·¹
}

def get_genre_by_emotion(emotion):
    """ê°ì •ì— ë§ëŠ” ì˜í™” ì¥ë¥´ IDë¥¼ ëœë¤ìœ¼ë¡œ ì„ íƒ"""
    genres = emotion_to_genre.get(emotion, [18])  # ê¸°ë³¸ê°’: ë“œë¼ë§ˆ(18)
    return random.choice(genres)

# ==========================================================
# âœ… 6. /emotion ì—”ë“œí¬ì¸íŠ¸
# ==========================================================
@app.route("/emotion", methods=["POST"])
def emotion_endpoint():
    """
    ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë¬¸ì¥ì—ì„œ ê°ì •ì„ ì˜ˆì¸¡í•˜ê³ 
    TMDB ì¥ë¥´ì— ë§ëŠ” ì˜í™” ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•¨.
    """
    try:
        data = request.get_json()
        user_input = data.get("emotion", "").strip()

        if not user_input:
            return jsonify({"reply": "ê°ì •ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”"}), 400

        # ëŒ€í‘œê°ì • ì˜ˆì¸¡
        X = vectorizer.transform([user_input])
        predicted_emotion = model.predict(X)[0]

        # í•´ë‹¹ ëŒ€í‘œê°ì •ì— ë§ëŠ” ì„¸ë¶€ê°ì • ëª¨ë¸ ì‚¬ìš© (ë‹¨ì¼ ëª¨ë¸ ë²„ì „)
        try:
            X_sub = sub_vectorizer.transform([user_input])
            predicted_sub = sub_model.predict(X_sub)[0]
        except Exception as e:
            print("ì„¸ë¶€ê°ì • ë¶„ì„ ì˜¤ë¥˜:", e)
            predicted_sub = "ì„¸ë¶€ê°ì • ì—†ìŒ"

        # ê°ì •ì— ë§ëŠ” ì˜í™” ì¥ë¥´ â†’ ì˜í™” ì¶”ì²œ
        genre_id = get_genre_by_emotion(predicted_emotion)
        movies = get_movies_by_genre(genre_id)

        return jsonify({
            "emotion": predicted_emotion,
            "sub_emotion": predicted_sub,
            "movies": movies
        })

    except Exception as e:
        print("âŒ /emotion ì˜¤ë¥˜:", e)
        return jsonify({"reply": "ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”"}), 500

# ==========================================================
# âœ… 7. /chat ì—”ë“œí¬ì¸íŠ¸ (3í„´ ê°ì •ìƒë‹´ + ì¶”ì²œ ëŒ€í™”)
# ==========================================================
conversation_history = []          # ì‚¬ìš©ìì™€ì˜ ëŒ€í™” ë‚´ì—­ ì €ì¥
recommended_movies_memory = []     # ì¶”ì²œ ì˜í™” ê¸°ì–µìš©

@app.route("/chat", methods=["POST"])
def chat_turn():
    """
    ì‚¬ìš©ìì˜ ê°ì • ëŒ€í™”ë¥¼ 3í„´ìœ¼ë¡œ êµ¬ì„±:
    1~2í„´: ê³µê°í˜• ëŒ€í™”
    3í„´: ê°ì • ìš”ì•½ â†’ ê°ì • ë¶„ì„ â†’ ì˜í™” ì¶”ì²œ
    ì´í›„: ì˜í™” ê´€ë ¨ ëŒ€í™” (í‰ì , ì¤„ê±°ë¦¬ ë“±)
    """
    try:
        data = request.get_json()
        user_msg = data.get("message", "")
        turn = data.get("turn", 1)
        gpt_reply = ""

        # turn ë°ì´í„° íƒ€ì… ì •ë¦¬ (ë¬¸ì or ìˆ«ì)
        if isinstance(turn, str):
            if turn == "after_recommend":
                turn_type = "after_recommend"
            else:
                try:
                    turn = int(turn)
                    turn_type = "normal"
                except ValueError:
                    turn_type = "normal"
        else:
            turn_type = "normal"

        global conversation_history
        conversation_history.append({"role": "user", "content": user_msg})

        # -----------------------------------------------
        # ğŸ§¡ 1~2í„´: ê°ì •ìƒë‹´ (ê³µê°í˜• ëŒ€í™”)
        # -----------------------------------------------
        if turn_type == "normal" and turn < 3:
            system_prompt = (
                "ë„ˆëŠ” ê°ì •ìƒë‹´ ì¹œêµ¬ì•¼. "
                "ì‚¬ìš©ìì˜ ë§ì„ ë”°ëœ»í•˜ê²Œ ê³µê°í•˜ë©´ì„œ ì§§ê²Œ ë‹µí•˜ê³ , "
                "ë°˜ë“œì‹œ ë§ˆì§€ë§‰ì— ì§ˆë¬¸ì„ í•˜ë‚˜ ë§ë¶™ì—¬."
                "ì‚¬ìš©ìì™€ ë„ˆê°€ í•œë§ì„ ëª¨ë‘ ê¸°ì–µí•´"
            )

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_msg},
                ],
            )
            gpt_reply = response.choices[0].message.content.strip()
            conversation_history.append({"role": "assistant", "content": gpt_reply})
            return jsonify({"reply": gpt_reply, "final": False})

        # -----------------------------------------------
        # ğŸï¸ ì¶”ì²œ ì´í›„ì˜ ëŒ€í™” (ì˜í™” ê´€ë ¨ ì§ˆì˜ì‘ë‹µ)
        # -----------------------------------------------
        elif turn_type == "after_recommend":
            try:
                followup_prompt = (
                    "ë„ˆëŠ” ê°ì • ê¸°ë°˜ ì˜í™” ì¶”ì²œ ì¹œêµ¬ì•¼. "
                    "ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ì™€ ì¶”ì²œí•œ ì˜í™”ë“¤ì„ ì „ë¶€ ê¸°ì–µí•˜ê³  ìˆì–´. "
                    "ì‚¬ìš©ìê°€ ì˜í™” ì œëª© ì¼ë¶€ë‚˜ ë²ˆí˜¸(1, 2, 3ë²ˆ)ë§Œ ë§í•´ë„ ì–´ë–¤ ì˜í™”ë¥¼ ì˜ë¯¸í•˜ëŠ”ì§€ ì•Œì•„ë“¤ì–´ì•¼ í•´. "
                    "â€˜ê·¸ê±°â€™, â€˜ì´ê±°â€™, â€˜ë§ˆì§€ë§‰êº¼â€™, â€˜ì²«ë²ˆì§¸êº¼â€™ ê°™ì€ í‘œí˜„ë„ ì´í•´í•´. "
                    "ì‚¬ìš©ìê°€ í‰ì ì´ë‚˜ ì¤„ê±°ë¦¬, ë°°ìš°, ë¶„ìœ„ê¸° ë“±ì„ ë¬¼ìœ¼ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì¤˜. "
                    "ì‘ë‹µì€ ì§§ê³  ìì—°ìŠ¤ëŸ½ê²Œ, ì¹œêµ¬ì²˜ëŸ¼ ë”°ëœ»í•˜ê²Œ ëŒ€í™”í•´."
                    "ì´ë¯¸ ì„¤ëª…í–ˆë˜ ì˜í™”ì— ëŒ€í•´ ë‹¤ì‹œ ë¬»ì§€ ì•ŠëŠ” ì´ìƒ, ìƒˆë¡œìš´ í‘œí˜„ìœ¼ë¡œ ì§§ê²Œ ì´ì–´ì„œ ë§í•´. "
                    "ì´ë¯¸ í•œ ë§ì„ ë‹¤ì‹œ í•˜ì§€ ë§ê³ , ëŒ€í™”ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ìŒ ì£¼ì œë¡œ ì´ì–´ì§€ê²Œ ë§í•´."
                    "ì‚¬ìš©ìê°€ ì¶”ì²œí•´ì¤€ ì˜í™”ë¥¼ ë§ˆìŒì— ë“¤ì–´í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ "
                    "ê°™ì€ ì˜í™”ë¥¼ ë‹¤ì‹œ ì–¸ê¸‰í•˜ì§€ ë§ê³  ìƒˆë¡œìš´ ì˜í™”ë¥¼ ì œì•ˆí•´ì¤˜."
                    "ì‚¬ìš©ìê°€ ìƒˆë¡œìš´ ì˜í™”ë¥¼ ë³´ê² ë‹¤ê³  í•˜ë©´, ê·¸ ì˜í™”ë¥¼ ê°€ì¥ ìµœê·¼ ì¶”ì²œìœ¼ë¡œ ê¸°ì–µí•´. "
                    "ê·¸ ì´í›„ í‰ì ì´ë‚˜ ì„¤ëª…ì„ ë¬¼ìœ¼ë©´ ê·¸ ì˜í™” ê¸°ì¤€ìœ¼ë¡œ ë‹µí•´."                
                   
                )

                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": followup_prompt},
                        *conversation_history,
                        {"role": "user", "content": user_msg},
                    ],
                )
                gpt_reply = response.choices[0].message.content.strip()

                # ì‚¬ìš©ìê°€ í‰ì ì„ ë¬¼ì–´ë³¼ ê²½ìš° ì²˜ë¦¬
                lower_msg = user_msg.lower()
                if any(word in lower_msg for word in ["í‰ì ", "ì ìˆ˜", "ëª‡ì ", "ì "]):
                    movie_titles = recommended_movies_memory
                    candidate = None
                    # ëŒ€í™” ì† ì˜í™” ì œëª© íƒìƒ‰
                    for title in movie_titles:
                        if title.lower().replace(" ", "") in lower_msg:
                            candidate = title.strip()
                            break
                    # ëª…ì‹œë˜ì§€ ì•Šì€ ê²½ìš° ì²« ë²ˆì§¸ ì˜í™”ë¡œ ëŒ€ì²´
                    if not candidate and movie_titles:
                        candidate = movie_titles[0].strip()

                    # TMDB APIë¡œ í‰ì  ì¡°íšŒ
                    if candidate:
                        result = get_movie_rating(candidate)
                        if result:
                            gpt_reply += f"\nğŸ¬ '{result['title']}'ì˜ TMDB í‰ì ì€ {result['rating']}ì ì´ì—ìš”!"
                        else:
                            gpt_reply += f"\n'{candidate}'ì˜ í‰ì ì„ ì°¾ì§€ ëª»í–ˆì–´ìš” ğŸ˜¢"

                return jsonify({"reply": gpt_reply})

            except Exception as e:
                print("âŒ after_recommend ì˜¤ë¥˜:", e)
                return jsonify({"reply": "ì˜í™” ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš” ğŸ˜¢"}), 500

        # -----------------------------------------------
        # ğŸ§  3í„´: ìš”ì•½ + ê°ì • ë¶„ì„ + ì˜í™” ì¶”ì²œ
        # -----------------------------------------------
        recent_history = conversation_history[-6:]  # ìµœê·¼ 3í„´(ìœ ì €+ì±—ë´‡)ë§Œ ì‚¬ìš©

        summary_prompt = f"""
        ë‹¤ìŒì€ ì‚¬ìš©ìì™€ ê°ì •ìƒë‹´ ì±—ë´‡ì˜ ìµœê·¼ ëŒ€í™”ì•¼:
        {recent_history}
        ì‚¬ìš©ìì˜ í˜„ì¬ ê°ì • ìƒíƒœë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.
        ì˜ˆ: 'ìš”ì¦˜ ë§ˆìŒì´ ê³µí—ˆí•œê°€ ë´.', 'í”¼ê³¤í•´ì„œ ê¸°ìš´ì´ ì—†ëŠ” ìƒíƒœì•¼.'
        """

        # GPTë¡œ ê°ì • ìš”ì•½ ìƒì„±
        summary_response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ê°ì •ì„ ë”°ëœ»í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì¹œêµ¬ì•¼."},
                {"role": "user", "content": summary_prompt},
            ],
        )
        summary_text = summary_response.choices[0].message.content.strip()
        print("ğŸ§  ëŒ€í™” ìš”ì•½ë¬¸:", summary_text.encode("utf-8", "ignore").decode("utf-8"))

        # ëŒ€í‘œê°ì • ì˜ˆì¸¡
        X = vectorizer.transform([summary_text])
        predicted_emotion = model.predict(X)[0]

        # ëŒ€í‘œê°ì •ë³„ ì„¸ë¶€ê°ì • ì˜ˆì¸¡
        try:
            vec = sub_vectorizer.get(predicted_emotion)
            model_for_emotion = sub_model.get(predicted_emotion)
            if vec is not None and model_for_emotion is not None:
                X_sub = vec.transform([summary_text])
                # ğŸ”½ ì—¬ê¸°ì„œ í™•ë¥  ê¸°ë°˜ìœ¼ë¡œ ìµœê³  ì„¸ë¶€ê°ì • ì„ íƒ
                probs = model_for_emotion.predict_proba(X_sub)[0]
                classes = model_for_emotion.classes_
                predicted_sub = classes[probs.argmax()]
            else:
                predicted_sub = "ì„¸ë¶€ê°ì • ì—†ìŒ"
        except Exception as e:
            print("ì„¸ë¶€ê°ì • ë¶„ì„ ì˜¤ë¥˜:", e)
            predicted_sub = "ì„¸ë¶€ê°ì • ì—†ìŒ"

        # ê°ì •ì— ë§ëŠ” ì˜í™” ì¶”ì²œ
        genre_id = get_genre_by_emotion(predicted_emotion)
        movies = get_movies_by_genre(genre_id)
        movie_titles = [m["title"] for m in movies if isinstance(m, dict)]

        # ì¶”ì²œ ì˜í™” ëª©ë¡ì„ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì €ì¥
        conversation_history.append({
            "role": "assistant",
            "content": f"ì¶”ì²œ ì˜í™” ëª©ë¡ì€ {', '.join(movie_titles)}ì•¼."
        })
        conversation_history.append({
            "role": "assistant",
            "content": "ë‚´ê°€ ì¶”ì²œí•´ì¤€ ì˜í™”ê°€ ë§ˆìŒì— ë“¤ì–´? ğŸ¬"
        })

        return jsonify({
            "reply": gpt_reply,
            "summary": summary_text,
            "final": True,
            "emotion": predicted_emotion,
            "sub_emotion": predicted_sub,
            "movies": movies
        })

    except Exception as e:
        print("âŒ /chat ì˜¤ë¥˜:", e)
        return jsonify({"reply": "ì„œë²„ ì˜¤ë¥˜ ë°œìƒ"}), 500

# ==========================================================
# âœ… 8. HTML íŒŒì¼ ì œê³µ (í”„ë¡ íŠ¸ì—”ë“œ ì—°ê²°)
# ==========================================================
@app.route("/")
def home():
    """index.html íŒŒì¼ì„ ë°˜í™˜ (ì›¹ì•± ì§„ì…ì )"""
    return send_from_directory(BASE_DIR, "index.html")

# ==========================================================
# âœ… 9. DB ì—°ê²° ë° í†µê³„ API
# ==========================================================
DB_PASSWORD = os.getenv("DB_PASSWORD")

def get_connection():
    """MySQL ì—°ê²° í•¨ìˆ˜"""
    return pymysql.connect(
        host="localhost",
        user="root",
        password=DB_PASSWORD,
        db="moodymovie",
        charset="utf8mb4",
        cursorclass=pymysql.cursors.DictCursor,
    )

# ê°ì •ë³„ ì¹´ìš´íŠ¸ í†µê³„
@app.route("/stats")
def get_stats():
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute("""
        SELECT rep_emotion, COUNT(*) AS count
        FROM movies_emotions
        GROUP BY rep_emotion
        ORDER BY count DESC;
    """)
    result = cursor.fetchall()
    conn.close()
    return jsonify(result)

# ê°€ì¥ ë§ì´ ì¶”ì²œëœ ì˜í™” TOP10
@app.route("/top10")
def get_top10_movies():
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute("""
        SELECT movie, COUNT(*) AS count
        FROM movies_emotions
        GROUP BY movie
        ORDER BY count DESC
        LIMIT 10;
    """)
    result = cursor.fetchall()
    conn.close()
    return jsonify(result)

# ==========================================================
# âœ… 10. Flask ì„œë²„ ì‹¤í–‰
# ==========================================================
if __name__ == "__main__":
    # 0.0.0.0 â†’ ì™¸ë¶€ì—ì„œë„ ì ‘ê·¼ ê°€ëŠ¥
    app.run(host="0.0.0.0", port=5000, debug=True, use_reloader=False)
