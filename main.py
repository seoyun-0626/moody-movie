import json
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from flask.json.provider import DefaultJSONProvider
import pickle, random, sys
from openai import OpenAI
from movie_api import get_movies_by_genre  
from dotenv import load_dotenv
import os

# âœ… .env íŒŒì¼ ê°•ì œ ë¡œë“œ
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), ".env"))

api_key = os.getenv("OPENAI_API_KEY")
print(f"ğŸ”‘ OpenAI Key ë¶ˆëŸ¬ì˜´: {api_key[:10]}...")  # í‚¤ í™•ì¸ìš©

# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = OpenAI(api_key=api_key)

# ==========================
# Flask ì„¤ì •
# ==========================
app = Flask(__name__)

# âœ… ëª¨ë“  ë„ë©”ì¸ì—ì„œ ì ‘ê·¼ í—ˆìš©
CORS(app, resources={r"/*": {"origins": "*"}})

app.config['JSON_AS_ASCII'] = False  # âœ… jsonifyê°€ í•œê¸€ì„ ASCIIë¡œ ë³€í™˜í•˜ì§€ ì•Šë„ë¡ ì„¤ì •
class UTF8JSONProvider(DefaultJSONProvider):
    def dumps(self, obj, **kwargs):
        kwargs.setdefault("ensure_ascii", False)
        return json.dumps(obj, **kwargs)
    def loads(self, s, **kwargs):
        return json.loads(s, **kwargs)
app.json = UTF8JSONProvider(app)

sys.stdout.reconfigure(encoding='utf-8')


# ==========================
# ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ
# ==========================
try:
    model = pickle.load(open("models/emotion_model.pkl", "rb"))
    sub_model = pickle.load(open("models/emotion_sub_model.pkl", "rb"))
    vectorizer = pickle.load(open("models/vectorizer.pkl", "rb"))
    sub_vectorizer = pickle.load(open("models/sub_vectorizers.pkl", "rb"))
    print("âœ… ê°ì • ë¶„ì„ ëª¨ë¸ ë° ì„¸ë¶€ê°ì • ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit()

# ==========================
# ê°ì • â†’ ì¥ë¥´ ë§¤í•‘
# ==========================
emotion_to_genre = {
    "ë¶„ë…¸": [28, 80, 53, 27, 9648],
    "ë¶ˆì•ˆ": [53, 9648, 18, 878],
    "ìŠ¤íŠ¸ë ˆìŠ¤": [35, 10402, 10751, 16],
    "ìŠ¬í””": [18, 10749, 10751, 99],
    "í–‰ë³µ": [12, 35, 16, 10751, 10402],
    "ì‹¬ì‹¬": [14, 878, 12, 10751],
    "íƒêµ¬": [99, 36, 18, 37],
}
def get_genre_by_emotion(emotion):
    genres = emotion_to_genre.get(emotion, [18])
    return random.choice(genres)

# ==========================
# âœ… /emotion ì—”ë“œí¬ì¸íŠ¸ (ê°ì • ë¶„ì„ + ì„¸ë¶€ê°ì • + ì˜í™” ì¶”ì²œ)
# ==========================
@app.route("/emotion", methods=["POST"])
def emotion_endpoint():
    try:
        data = request.get_json()
        user_input = data.get("emotion", "").strip()

        if not user_input:
            return jsonify({"reply": "ê°ì •ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”"}), 400

        # ëŒ€í‘œ ê°ì • ì˜ˆì¸¡
        X = vectorizer.transform([user_input])
        predicted_emotion = model.predict(X)[0]

        # ì„¸ë¶€ ê°ì • ì˜ˆì¸¡
        try:
            X_sub = sub_vectorizer.transform([user_input])
            predicted_sub = sub_model.predict(X_sub)[0]
        except Exception:
            predicted_sub = "ì„¸ë¶€ê°ì • ì—†ìŒ"

        # ê°ì •ì— ë§ëŠ” ì¥ë¥´ â†’ ì˜í™” ì¶”ì²œ
        genre_id = get_genre_by_emotion(predicted_emotion)
        movies = get_movies_by_genre(genre_id)

        # ê²°ê³¼ ë°˜í™˜
        return jsonify({
            "emotion": predicted_emotion,
            "sub_emotion": predicted_sub,
            "movies": movies
        })

    except Exception as e:
        print("âŒ /emotion ì˜¤ë¥˜:", e)
        return jsonify({"reply": "ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”"}), 500


# ==========================
# âœ… 3í„´ ëŒ€í™”ìš© /chat ì—”ë“œí¬ì¸íŠ¸
# ==========================
conversation_history = []

@app.route("/chat", methods=["POST"])
def chat_turn():
    try:
        data = request.get_json()
        user_msg = data.get("message", "")
        turn = data.get("turn", 1)
        gpt_reply = ""

        # âœ… ë¬¸ìì—´ê³¼ ìˆ«ì êµ¬ë¶„
        if isinstance(turn, str):
            if turn == "after_recommend":
                turn_type = "after_recommend"
            else:
                try:
                    turn = int(turn)
                    turn_type = "normal"
                except ValueError:
                    turn_type = "normal"
        else:
            turn_type = "normal"

        global conversation_history
        conversation_history.append({"role": "user", "content": user_msg})

        # 1~2í„´ ëŒ€í™”
        if turn_type == "normal" and turn < 3:
            system_prompt = (
                "ë„ˆëŠ” ê°ì •ìƒë‹´ ì¹œêµ¬ì•¼. "
                "ì‚¬ìš©ìì˜ ë§ì„ ë”°ëœ»í•˜ê²Œ ê³µê°í•˜ë©´ì„œ ì§§ê²Œ ë‹µí•˜ê³ , "
                "ë°˜ë“œì‹œ ë§ˆì§€ë§‰ì— ì§ˆë¬¸ì„ í•˜ë‚˜ ë§ë¶™ì—¬."
            )
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_msg},
                ],
            )
            gpt_reply = response.choices[0].message.content.strip()
            conversation_history.append({"role": "assistant", "content": gpt_reply})
            return jsonify({"reply": gpt_reply, "final": False})

        # âœ… ì¶”ì²œ ì´í›„ ëŒ€í™”
        elif turn_type == "after_recommend":
            followup_prompt = (
                "ë„ˆëŠ” ê°ì • ê¸°ë°˜ ì˜í™” ì¶”ì²œì„ ì´ì–´ê°€ëŠ” ì¹œêµ¬ì•¼. "
                "ë„ˆëŠ” ì˜í™”ì— ëŒ€í•œ ì–˜ê¸°ë§Œ ê°€ëŠ¥í•˜ê³  ë‹¤ë¥¸ì§ˆë¬¸ì€ ë‹µë³€ ì–´ë µë‹¤ê³  í•´ì•¼í•´."
                "ë°©ê¸ˆ ë„¤ê°€ ì¶”ì²œí•œ ì˜í™” ëª©ë¡ì€ ì´ë¯¸ ëŒ€í™” ê¸°ë¡ì— ì €ì¥ë˜ì–´ ìˆì–´. "
                "ì‚¬ìš©ìê°€ ê·¸ ì˜í™”ë“¤ ì¤‘ í•˜ë‚˜ë¥¼ ì–¸ê¸‰í•˜ë©´, "
                "ê·¸ ì˜í™”ì— ëŒ€í•´ ì´ë¯¸ ë³¸ ê²ƒì²˜ëŸ¼ ë§í•˜ì§€ ë§ê³ , "
                "â€˜ê·¸ ì˜í™”ëŠ” ì•¡ì…˜ì´ ê°•í•´ì„œ ë„ˆí•œí…Œ ì˜ ì–´ìš¸ë¦´ ìˆ˜ë„ ìˆê² ë‹¤â€™ ê°™ì€ ì‹ìœ¼ë¡œ ê°€ë³ê²Œ ë°˜ì‘í•´. "
                "ë˜í•œ ì‚¬ìš©ìê°€ ì˜í™”ì˜ í‰ì ì´ë‚˜ ì •ë³´ë¥¼ ë¬¼ìœ¼ë©´, "
                "â€˜TMDB ê¸°ì¤€ í‰ì ì„ í™•ì¸í•´ë³¼ê²Œâ€™ ê°™ì€ ì‹ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€."
            )
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": followup_prompt},
                    *conversation_history,  # âœ… ì´ì „ ëŒ€í™” ë§¥ë½ ì¶”ê°€
                    {"role": "user", "content": user_msg},
                ],
            )
            gpt_reply = response.choices[0].message.content.strip()
            return jsonify({"reply": gpt_reply})

        # âœ… 3í„´ ëŒ€í™” â†’ ìš”ì•½ + ê°ì •ë¶„ì„ + ì¶”ì²œ
        else:
            closing_prompt = (
                "ë„ˆëŠ” ê°ì •ìƒë‹´ ì¹œêµ¬ì•¼. "
                "ì´ì œ ëŒ€í™”ë¥¼ ë§ˆë¬´ë¦¬í•˜ë©´ì„œ ì§§ê²Œ ê³µê°ë§Œ í•˜ê³  ì§ˆë¬¸ì€ í•˜ì§€ ë§ˆ."
            )
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": closing_prompt},
                    {"role": "user", "content": user_msg},
                ],
            )
            gpt_reply = response.choices[0].message.content.strip()
            conversation_history.append({"role": "assistant", "content": gpt_reply})

            # âœ… ìš”ì•½ë¬¸ ìƒì„±
            summary_prompt = f"""
            ë‹¤ìŒì€ ì‚¬ìš©ìì™€ ê°ì •ìƒë‹´ ì±—ë´‡ì˜ 3í„´ ëŒ€í™”ì•¼:
            {conversation_history}
            ì‚¬ìš©ìì˜ ê°ì • ìƒíƒœë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.
            ì˜ˆ: 'ìš”ì¦˜ ë§ˆìŒì´ ê³µí—ˆí•œê°€ ë´.', 'í”¼ê³¤í•´ì„œ ê¸°ìš´ì´ ì—†ëŠ” ìƒíƒœì•¼.'
            """
            summary_response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ê°ì •ì„ ë”°ëœ»í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì¹œêµ¬ì•¼."},
                    {"role": "user", "content": summary_prompt},
                ],
            )
            summary_text = summary_response.choices[0].message.content.strip()
            print("ğŸ§  ëŒ€í™” ìš”ì•½ë¬¸:", summary_text.encode('utf-8', 'ignore').decode('utf-8'))

            # âœ… ê°ì • ë¶„ì„ ì‹¤í–‰
            X = vectorizer.transform([summary_text])
            predicted_emotion = model.predict(X)[0]

            try:
                X_sub = sub_vectorizer.transform([summary_text])
                predicted_sub = sub_model.predict(X_sub)[0]
            except Exception as e:
                print("ì„¸ë¶€ê°ì • ë¶„ì„ ì˜¤ë¥˜:", e)
                predicted_sub = "ì„¸ë¶€ê°ì • ì—†ìŒ"

            genre_id = get_genre_by_emotion(predicted_emotion)
            movies = get_movies_by_genre(genre_id)
            
            # âœ… GPTê°€ ë‹¤ìŒ í„´(after_recommend)ì—ì„œ ì˜í™” ì œëª©ë“¤ì„ ê¸°ì–µí•  ìˆ˜ ìˆê²Œ ì €ì¥
            movie_titles = [m["title"] for m in movies if isinstance(m, dict)]
            conversation_history.append({
                "role": "assistant",
                "content": f"ì¶”ì²œ ì˜í™” ëª©ë¡ì€ {', '.join(movie_titles)}ì•¼."
                })

        
            # âœ… ëŒ€í™” ì´ˆê¸°í™”
            # conversation_history = []

            return jsonify({
                "reply": gpt_reply,
                "summary": summary_text,
                "final": True,
                "emotion": predicted_emotion,
                "sub_emotion": predicted_sub,
                "movies": movies
            })

    # âœ… ì´ê²Œ ë°˜ë“œì‹œ ë“¤ì–´ê°€ì•¼ í•¨ (ì˜¤ë¥˜ì˜ ì›ì¸)
    except Exception as e:
        print("âŒ /chat ì˜¤ë¥˜:", e)
        return jsonify({"reply": "ì„œë²„ ì˜¤ë¥˜ ë°œìƒ"}), 500


# ==========================
# HTML ì—°ê²°
# ==========================
@app.route("/")
def home():
    return send_from_directory(".", "index.html")


# ==========================
# DB ì—°ê²° ë° í†µê³„ API 
# ==========================
import pymysql
from dotenv import load_dotenv
import os

load_dotenv()  # .env ì½ê¸°
DB_PASSWORD = os.getenv("DB_PASSWORD")

def get_connection():
    return pymysql.connect(
        host="localhost",
        user="root",
        password=DB_PASSWORD,  
        db="moodymovie",
        charset="utf8mb4",
        cursorclass=pymysql.cursors.DictCursor,
    )

@app.route("/stats")
def get_stats():
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute("""
        SELECT rep_emotion, COUNT(*) AS count
        FROM movies_emotions
        GROUP BY rep_emotion
        ORDER BY count DESC;
    """)
    result = cursor.fetchall()
    conn.close()
    return jsonify(result)

#ë§ì´ ì¶”ì²œëœ ì˜í™” íƒ‘10

@app.route("/top10")
def get_top10_movies():
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute("""
        SELECT movie, COUNT(*) AS count
        FROM movies_emotions
        GROUP BY movie
        ORDER BY count DESC
        LIMIT 10;
    """)
    result = cursor.fetchall()
    conn.close()
    return jsonify(result)


# ==========================
# ì„œë²„ ì‹¤í–‰
# ==========================
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True, use_reloader=False)
